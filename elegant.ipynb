{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ELEGANT: Face Attribute Editing\n",
        "This notebook implements the ELEGANT model for face attribute editing using GANs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from PIL import Image\n",
        "import time\n",
        "from tensorboardX import SummaryWriter\n",
        "import argparse\n",
        "\n",
        "print(f\"PyTorch CUDA Version: {torch.version.cuda}\")\n",
        "print(f\"torchvision CUDA Version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration and Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config:\n",
        "    @property\n",
        "    def data_dir(self):\n",
        "        data_dir = './datasets/celebA'\n",
        "        if not os.path.exists(data_dir):\n",
        "            os.makedirs(data_dir)\n",
        "        return data_dir\n",
        "\n",
        "    @property\n",
        "    def exp_dir(self):\n",
        "        exp_dir = os.path.join('train_log')\n",
        "        if not os.path.exists(exp_dir):\n",
        "            os.makedirs(exp_dir)\n",
        "        return exp_dir\n",
        "\n",
        "    @property\n",
        "    def model_dir(self):\n",
        "        model_dir = os.path.join(self.exp_dir, 'model')\n",
        "        if not os.path.exists(model_dir):\n",
        "            os.makedirs(model_dir)\n",
        "        return model_dir\n",
        "\n",
        "    @property\n",
        "    def log_dir(self):\n",
        "        log_dir = os.path.join(self.exp_dir, 'log')\n",
        "        if not os.path.exists(log_dir):\n",
        "            os.makedirs(log_dir)\n",
        "        return log_dir\n",
        "\n",
        "    @property\n",
        "    def img_dir(self):\n",
        "        img_dir = os.path.join(self.exp_dir, 'img')\n",
        "        if not os.path.exists(img_dir):\n",
        "            os.makedirs(img_dir)\n",
        "        return img_dir\n",
        "\n",
        "    # Model parameters\n",
        "    nchw = [16,3,256,256]\n",
        "    G_lr = 2e-4\n",
        "    D_lr = 2e-4\n",
        "    betas = [0.5, 0.999]\n",
        "    weight_decay = 1e-5\n",
        "    step_size = 3000\n",
        "    gamma = 0.97\n",
        "    shuffle = True\n",
        "    num_workers = 4\n",
        "    max_iter = 200000\n",
        "    num_samples = None\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SingleCelebADataset(Dataset):\n",
        "    def __init__(self, im_names, labels, config):\n",
        "        self.im_names = im_names\n",
        "        self.labels = labels\n",
        "        self.config = config\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.im_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.im_names[idx])\n",
        "        image = self.transform(image) * 2 - 1\n",
        "        label = (self.labels[idx] + 1) / 2\n",
        "        return image, label\n",
        "\n",
        "    @property\n",
        "    def transform(self):\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(self.config.nchw[-2:]),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        return transform\n",
        "\n",
        "    def gen(self):\n",
        "        dataloader = DataLoader(self,\n",
        "                                batch_size=self.config.nchw[0],\n",
        "                                shuffle=self.config.shuffle,\n",
        "                                num_workers=self.config.num_workers,\n",
        "                                drop_last=True)\n",
        "        while True:\n",
        "            for data in dataloader:\n",
        "                yield data\n",
        "\n",
        "    def file_exist(self):\n",
        "        for im_name in self.im_names:\n",
        "            if not os.path.exists(im_name):\n",
        "                print(\"File not found:\", im_name)\n",
        "                return False\n",
        "        return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiCelebADataset(object):\n",
        "    def __init__(self, attributes, config=config):\n",
        "        self.attributes = attributes\n",
        "        self.config = config\n",
        "\n",
        "        with open(os.path.join(self.config.data_dir, 'list_attr_celeba.txt'), 'r') as f:\n",
        "            lines = f.read().strip().split('\\n')\n",
        "            col_ids = [lines[1].split().index(attribute) + 1 for attribute in self.attributes]\n",
        "            self.all_labels = np.array([[int(x.split()[col_id]) for col_id in col_ids] for x in lines[2:]], dtype=np.float32)\n",
        "            self.im_names = np.array([os.path.join(self.config.data_dir,\n",
        "                                                   'align_5p/{:06d}.jpg'.format(idx+1)) for idx in range(len(self.all_labels))])\n",
        "\n",
        "        if self.config.num_samples is not None:\n",
        "            self.all_labels = self.all_labels[:self.config.num_samples]\n",
        "            self.im_names = self.im_names[:self.config.num_samples]\n",
        "        print(\"Total images:\",len(self.im_names))\n",
        "\n",
        "        self.dict = {i: {True: None, False: None} for i in range(len(self.attributes))}\n",
        "        for attribute_id in range(len(self.attributes)):\n",
        "            for is_positive in [True, False]:\n",
        "                idxs = np.where(self.all_labels[:,attribute_id] == (int(is_positive)*2 - 1))[0]\n",
        "                im_names = self.im_names[idxs]\n",
        "                labels = self.all_labels[idxs]\n",
        "                data_gen = SingleCelebADataset(im_names, labels, self.config).gen()\n",
        "                self.dict[attribute_id][is_positive] = data_gen\n",
        "\n",
        "    def gen(self, attribute_id, is_positive):\n",
        "        return self.dict[attribute_id][is_positive]\n",
        "\n",
        "    def file_exist(self):\n",
        "        cnt = 0\n",
        "        for im_name in self.im_names:\n",
        "            if not os.path.exists(im_name):\n",
        "                print(\"File not found:\", im_name)\n",
        "            else:\n",
        "                cnt = cnt + 1\n",
        "        return cnt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NTimesTanh(nn.Module):\n",
        "    def __init__(self, N):\n",
        "        super(NTimesTanh, self).__init__()\n",
        "        self.N = N\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.tanh(x) * self.N\n",
        "\n",
        "class Normalization(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Normalization, self).__init__()\n",
        "        self.alpha = Parameter(torch.ones(1))\n",
        "        self.beta  = Parameter(torch.zeros(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.nn.functional.normalize(x, dim=1)\n",
        "        return x * self.alpha + self.beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.main = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(3, 64, 3, 2, 1, bias=True),\n",
        "                Normalization(),\n",
        "                nn.LeakyReLU(negative_slope=0.2),\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(64, 128, 3, 2, 1, bias=True),\n",
        "                Normalization(),\n",
        "                nn.LeakyReLU(negative_slope=0.2),\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(128, 256, 3, 2, 1, bias=True),\n",
        "                Normalization(),\n",
        "                nn.LeakyReLU(negative_slope=0.2),\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(256, 512, 3, 2, 1, bias=True),\n",
        "                Normalization(),\n",
        "                nn.LeakyReLU(negative_slope=0.2),\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(512, 512, 3, 2, 1, bias=True),\n",
        "                Normalization(),\n",
        "                nn.LeakyReLU(negative_slope=0.2),\n",
        "            ),\n",
        "        ])\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.02)\n",
        "            elif isinstance(m, nn.ConvTranspose2d):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.02)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.normal_(m.weight, mean=1, std=0.02)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.02)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x, return_skip=True):\n",
        "        skip = []\n",
        "        for i in range(len(self.main)):\n",
        "            x = self.main[i](x)\n",
        "            if i < len(self.main) - 1:\n",
        "                skip.append(x)\n",
        "        if return_skip:\n",
        "            return x, skip\n",
        "        else:\n",
        "            return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.main = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.ConvTranspose2d(1024,512,3,2,1,1,bias=True),\n",
        "                Normalization(),\n",
        "                nn.ReLU(),\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.ConvTranspose2d(512,256,3,2,1,1,bias=True),\n",
        "                Normalization(),\n",
        "                nn.ReLU(),\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.ConvTranspose2d(256,128,3,2,1,1,bias=True),\n",
        "                Normalization(),\n",
        "                nn.ReLU(),\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.ConvTranspose2d(128,64,3,2,1,1,bias=True),\n",
        "                Normalization(),\n",
        "                nn.ReLU(),\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.ConvTranspose2d(64,3,3,2,1,1,bias=True),\n",
        "            ),\n",
        "        ])\n",
        "        self.activation = NTimesTanh(2)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.02)\n",
        "            elif isinstance(m, nn.ConvTranspose2d):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.02)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.normal_(m.weight, mean=1, std=0.02)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.02)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, enc1, enc2, skip=None):\n",
        "        x = torch.cat([enc1, enc2], 1)\n",
        "        for i in range(len(self.main)):\n",
        "            x = self.main[i](x)\n",
        "            if skip is not None and i < len(skip):\n",
        "                x = x + skip[-i-1]\n",
        "        return self.activation(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, n_attributes, img_size):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.n_attributes = n_attributes\n",
        "        self.img_size = img_size\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3+n_attributes,64,3,2,1,bias=True),\n",
        "            Normalization(),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "\n",
        "            nn.Conv2d(64,128,3,2,1,bias=True),\n",
        "            Normalization(),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "\n",
        "            nn.Conv2d(128,256,3,2,1,bias=True),\n",
        "            Normalization(),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "\n",
        "            nn.Conv2d(256,512,3,2,1,bias=True),\n",
        "            Normalization(),\n",
        "            nn.LeakyReLU(negative_slope=0.2),\n",
        "        )\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(512*(self.img_size//16)*(self.img_size//16), 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self.downsample = torch.nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.02)\n",
        "            elif isinstance(m, nn.ConvTranspose2d):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.02)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.normal_(m.weight, mean=1, std=0.02)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, mean=0, std=0.02)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, image, label):\n",
        "        while image.shape[-1] != self.img_size or image.shape[-2] != self.img_size:\n",
        "            image = self.downsample(image)\n",
        "        new_label = label.view((image.shape[0], self.n_attributes, 1, 1)).expand((image.shape[0], self.n_attributes, image.shape[2], image.shape[3]))\n",
        "        x = torch.cat([image, new_label], 1)\n",
        "        output = self.conv(x)\n",
        "        output = output.view(output.shape[0], -1)\n",
        "        output = self.linear(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of simulating command-line arguments\n",
        "args = argparse.Namespace(\n",
        "    attributes=['Arched_Eyebrows' ,'Black_Hair'],\n",
        "    gpu=[],\n",
        "    mode='train',\n",
        "    restore=None,\n",
        "    swap=False,\n",
        "    linear=False,\n",
        "    matrix=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"init model\")\n",
        "model = ELEGANT(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "main(args,model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
